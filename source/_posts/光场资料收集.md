---
title: 光场资料收集（转）
date: 2024-09-05 23:26:22
tags: 
- 光场 
- 计算成像
categories: 
- 资料汇总
cover: 
---
<h2 id="Links-About-Light-Field"><a href="#Links-About-Light-Field" class="headerlink" title="Links About Light Field"></a>Links About Light Field</h2><ul>
<li><a href="http://lightfield.stanford.edu/lfs.html" target="_blank" rel="external">斯坦福大学光场数据库</a>：老牌斯坦福大学计算机图形实验室(Computer Graphics Laboratory)提供的，该数据库所在网站还提供了光场的采集设备，相机标定以及可视化工具。</li>
<li>斯坦福大学计算机图形实验室的<a href="http://graphics.stanford.edu/~levoy/" target="_blank" rel="external">Marc Levoy</a>教授做的动画仿真，利于理解。<a href="https://graphics.stanford.edu/courses/cs178/applets/applets.html" target="_blank" rel="external">Flash applets on some technical aspects of photography</a>，这里面详细地介绍了相机的各种参数变化对应的光路图的变化，强烈推荐。</li>
<li><a href="http://hci-lightfield.iwr.uni-heidelberg.de/" target="_blank" rel="external">HCI光场数据集</a>，千呼万唤始出来，有好长一段时间这个数据集突然消失了（可能是在维护数据）。如今以新的面貌重现天日，真的让人喜出望外。对于其数据集，HCI提供的<a href="https://github.com/lightfield-analysis/matlab-tools" target="_blank" rel="external">解码工具</a>；这是要建立与<a href="#Middlebury">Middlebury</a>齐名的数据集（包括评价排名）的节奏啊！（ps:日后整理，很感兴趣）</li>
<li><a href="http://cseweb.ucsd.edu/~ravir/" target="_blank" rel="external"><strong>Ravi Ramamoorthi</strong></a>教授主页，一位计算成像，计算机视觉领域的大神，他所在组发表了很多高质量的文章，详情可参考他的主页。</li>
<li><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/" target="_blank" rel="external">光场实验室网站</a>，研究光场领域，隶属于<strong>Ravi Ramamoorthi</strong>教授。这里将是研究光场领域深度图像获取，三维重建以及去除高光等领域研究者的福音。</li>
<li>光场相机的缔造者以及Lytro公司的创始人<a href="http://www.eecs.berkeley.edu/Faculty/Homepages/yirenng.html/" target="_blank" rel="external">Ren Ng</a>。看这里是其创建的<a href="https://illum.lytro.com" target="_blank" rel="external">Lytro公司</a>的主页；最初Lytro的最大卖点在于<strong>先拍照后对焦</strong>，可是买账的人并不多；购买者多数是摄影爱好者以及科研机构。最近Lytro公司开始进军VR以及AR领域，看了下其设备，怎一个大字了得（Ps: 话说Ng为何去教书了？）</li>
<li><a href="http://blog.lytro.com/" target="_blank" rel="external">Lytro论坛</a>，这里有关于Lytro公司以及光场相机最新的应用，时常关注不至于落后于时代，不至于被世界残忍的抛弃。</li>
<li>MATLAB<a href="http://www.mathworks.com/matlabcentral/fileexchange/49683-light-field-toolbox-v0-4" target="_blank" rel="external">光场工具包</a>，这个工具包从事光场研究的科研人员的福利，后文中我将详细的介绍这个工具包的使用方法。</li>
<li><a href="http://optics.miloush.net/lytro/Default.aspx" target="_blank" rel="external"><strong>LytroMeltdown</strong></a>，一位布拉格大学(Charles University)的学生拆解Lytro 1.0的资料，如果你想对光场相机的内部结构有更加深入的了解的话，这个网址有丰富的介绍。（目前仅有Lytro一代的拆解并没有ILLUM的拆解，原因是过于昂贵，作者买不起）</li>
<li>cocolib<a href="http://sourceforge.net/p/cocolib/home/Home/" target="_blank" rel="external">光场工具套件</a>，这个套件实际上是一个处理凸优化问题的库，既可以用命令行操作也可Matlab界面操作。该库实现了目前集中常用的算法诸如： inverse problems，基于总变分最小化的图像分割以及矢量多标记交易成本函数；当然最重要的还有对于光场图像的分析函数套件（基于HCI发表的深度估计论文）。</li>
<li>著名的<a href="http://vision.middlebury.edu/stereo/" target="_blank" rel="external">Middlebury</a><span id="Middlebury">数据集</span>：来提供了Benchmark(左右视角的纹理图以及对应的GT深度图像)，各种算法的性能对比， 在双目深度估计领域属于最为权威的评估标准。</li>
<li>Deep learning: <a href="https://github.com/iro-cp/FCRN-DepthPrediction" target="_blank" rel="external">Depth Estimation</a>，目前基于双目，多目以及利用光场进行深度估计的算法已有很多；有些研究者利用当前比较火热的深度学习的策略对<strong>单幅图像</strong>进行深度图像的提取；我本来想跑跑人家代码，可以目前还没时间搞这些。</li>
<li><a href="http://cvlab.epfl.ch/" target="_blank" rel="external">Computer Vision Laboratory - CVLAB</a></li>
<li><a href="http://media.au.tsinghua.edu.cn/people.jsp" target="_blank" rel="external">宽带网数字媒体技术实验室</a>的<a href="http://www.liuyebin.com/" target="_blank" rel="external">Yebin Liu 刘烨斌主页</a></li>
<li>深度图+原始彩色图像转化成多视角动态gif，<a href="http://wigglemaker.ugocapeto.com/" target="_blank" rel="external">戳这里</a>，这算是深度图像的一个小小的应用。</li>
</ul>
<h2 id="Light-Field-Resources"><a href="#Light-Field-Resources" class="headerlink" title="Light Field Resources"></a><a href="https://github.com/Vincentqyw/light-field-resources/blob/master/README.md" target="_blank" rel="external">Light Field Resources</a></h2><p>This is a (work in progress) repo for collecting links to data sets, source code, and other resources related to research on light fields for computer vision.For further information and interaction within the light field community, have a look at:</p>
<ul>
<li><a href="https://plus.google.com/communities/114934462920613225440" target="_blank" rel="external">Google Community for the Matlab Light Field Toolbox</a></li>
<li><a href="http://lightfield-forum.com/en/" target="_blank" rel="external">Light Field Forum</a></li>
<li><a href="https://groups.google.com/forum/#!forum/lightfieldvision" target="_blank" rel="external">Mailing List / General Light Field Vision Google Group</a></li>
</ul>
<h2 id="Background-Information-General-Light-Field-Information"><a href="#Background-Information-General-Light-Field-Information" class="headerlink" title="Background Information / General Light Field Information"></a>Background Information / General Light Field Information</h2><ul>
<li><a href="https://en.wikipedia.org/wiki/Light_field" target="_blank" rel="external">Wikipedia</a></li>
<li><a href="http://plenoptic.info/" target="_blank" rel="external">plenoptic.info</a> provides some nice visualizations on how micro lens based plenoptic cameras work</li>
<li><a href="http://www.tgeorgiev.net/" target="_blank" rel="external">Todor Georgievs Website</a> insights into plenoptic cameras. No longer updated (?)</li>
<li><a href="http://lightfield-analysis.net/benchmark/paper/survey_cvprw_lf4cv_2017.pdf" target="_blank" rel="external">A Taxonomy and Evaluation of Dense Light Field Depth Estimation Algorithms</a> paper with an in depth overview of depth estimation approaches for 4D light fields</li>
<li><a href="https://web.stanford.edu/class/ee367/reading/levoy-lfphoto-ieee06.pdf" target="_blank" rel="external">Light Fields and Computational Imaging</a> early survey of the theory and practice of light field imaging </li>
<li><em>please add more :)</em></li>
</ul>
<h2 id="Other-Light-Field-Datasets"><a href="#Other-Light-Field-Datasets" class="headerlink" title="Other Light Field Datasets"></a>Other Light Field Datasets</h2><ul>
<li><a href="http://lightfield.stanford.edu/lfs.html" target="_blank" rel="external">The (New) Stanford Light Field Archive</a></li>
<li><a href="http://lightfields.stanford.edu/index.html" target="_blank" rel="external">Stanford Lytro Light Field Archive</a></li>
<li><a href="http://web.media.mit.edu/~gordonw/SyntheticLightFields/index.php" target="_blank" rel="external">MIT Synthetic Light Field Archive</a></li>
<li><a href="http://lightfield-analysis.net/" target="_blank" rel="external">4D Light Field Dataset (CVIA Konstanz &amp; HCI Heidelberg)</a></li>
<li><a href="http://lightfieldgroup.iwr.uni-heidelberg.de/?page_id=713" target="_blank" rel="external">HCI 4D Light Field Dataset</a></li>
<li><a href="https://www.irisa.fr/temics/demos/lightField/index.html" target="_blank" rel="external">Lytro first generation dataset</a></li>
<li><a href="http://mmspg.epfl.ch/EPFL-light-field-image-dataset" target="_blank" rel="external">EPFL Light-Field Image Dataset</a></li>
<li><a href="https://www.disneyresearch.com/project/lightfields/" target="_blank" rel="external">Disney High Spatio-Angular Resolution Light Fields</a></li>
<li><a href="https://www.eecis.udel.edu/~nianyi/LFSD.htm" target="_blank" rel="external">Light field Saliency Dataset (LFSD)</a></li>
<li><a href="https://github.com/aghasemi/lcav31" target="_blank" rel="external">LCAV-31 - A Dataset for Light Field Object Recognition</a></li>
<li><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV16/LF_dataset.zip" target="_blank" rel="external">A 4D Light-Field Dataset for Material Recognition</a></li>
<li><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ICCV15/dataset.zip" target="_blank" rel="external">Data for: Occlusion-aware depth estimation using light-field cameras</a></li>
<li><a href="https://vision.in.tum.de/data/datasets/ddff12scene" target="_blank" rel="external">DDFF 12-Scene 4.5D Lightfield-Depth Benchmark</a></li>
<li><em>please add more :)</em></li>
</ul>
<h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><ul>
<li><a href="http://dgd.vision/Tools/LFToolbox/" target="_blank" rel="external">Matlab Light Field Toolbox</a></li>
<li><a href="http://cocolib.net/index.php/examples/lightfields" target="_blank" rel="external">cocolib light field suite</a></li>
<li><a href="https://sites.google.com/site/yunsubok/lf_geo_calib" target="_blank" rel="external">Geometric light field camera calibration toolbox</a></li>
<li><a href="https://github.com/lightfield-analysis/blender-addon" target="_blank" rel="external">Blender addon to create synthetic light field data sets</a></li>
<li><em>please add more :)</em></li>
</ul>
<h2 id="Algorithm-Source-Code"><a href="#Algorithm-Source-Code" class="headerlink" title="Algorithm Source Code"></a>Algorithm Source Code</h2><ul>
<li><a href="https://sites.google.com/site/hgjeoncv/home/depthfromlf_cvpr15" target="_blank" rel="external">Accurate Depth Map Estimation from a Lenslet Light Field Camera</a> (*LF)</li>
<li><a href="http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ICCV15/occCode.zip" target="_blank" rel="external">Occlusion-aware depth estimation using light-field cameras</a> (*LF_OCC)</li>
<li><a href="http://www.ee.nthu.edu.tw/chaotsung/rprf/index.html" target="_blank" rel="external">Empirical Bayesian Light-Field Stereo Matching by Robust Pseudo Random Field Modeling</a> (RPRF)</li>
<li><a href="https://github.com/shuozh/Spinning-Parallelogram-Operator" target="_blank" rel="external">Robust Depth Estimation for Light Field via Spinning Parallelogram Operator</a> (SPO)</li>
<li><a href="https://github.com/chshin10/epinet" target="_blank" rel="external">EPINET: A Fully-Convolutional Neural Network using Epipolar Geometry for Depth from Light Field Images</a></li>
<li><a href="https://github.com/phuang17/DeepMVS" target="_blank" rel="external">DeepMVS: Learning Multi-View Stereopsis</a></li>
<li><a href="https://github.com/hosseinjavidnia/Depth-MultiCamera" target="_blank" rel="external">Total variation-based dense depth from multicamera array</a></li>
<li><a href="https://github.com/Vincentqyw/Depth-Estimation-Light-Field/tree/master/LF_DC" target="_blank" rel="external">Depth from Combining Defocus and Correspondence Using Light-Field Cameras</a></li>
<li><a href="https://github.com/Vincentqyw/Depth-Estimation-Light-Field/tree/master/CAE" target="_blank" rel="external">Robust Light Field Depth Estimation for Noisy Scene with Occlusion</a></li>
<li><a href="https://github.com/renlifei1994/LF_DEPTH_SHADING" target="_blank" rel="external">Depth from Shading, Defocus, and Correspondence Using Light-Field Angular Coherence</a></li>
<li><em>please add more :)</em></li>
</ul>
<p><em>Where applicable, the short name in parentheses denotes the acronym used on the <a href="http://lightfield-analysis.net" target="_blank" rel="external">4D light field benchmark</a>.</em></p>
<h2 id="Workshops-amp-Tutorials"><a href="#Workshops-amp-Tutorials" class="headerlink" title="Workshops &amp; Tutorials"></a>Workshops &amp; Tutorials</h2><ul>
<li><a href="https://www.eecis.udel.edu/~yu/LF4CV/" target="_blank" rel="external">1st Workshop on Light Fields for Computer Vision @ ECCV 2014</a></li>
<li><a href="http://lightfield-analysis.net/LF4CV/" target="_blank" rel="external">2nd Workshop on Light Fields for Computer Vision @ CVPR 2017</a></li>
<li><em>please add more :)</em></li>
</ul>
<h2 id="People-Labs"><a href="#People-Labs" class="headerlink" title="People / Labs"></a>People / Labs</h2><ul>
<li><a href="https://www.cvia.uni-konstanz.de/" target="_blank" rel="external">CVIA, Computer Vision and Image Analysis, Uni Konstanz, Germany</a></li>
<li><a href="http://www.computationalimaging.org/" target="_blank" rel="external">SCI, Stanford Computational Imaging, Stanford University, USA</a></li>
<li><a href="http://lightfieldgroup.iwr.uni-heidelberg.de/?page_id=453" target="_blank" rel="external">HCI, Heidelberg Collaboratory for Image Processing, Heidelberg University, Germany</a></li>
<li><a href="https://shuozh.github.io/" target="_blank" rel="external">Home Page for Shuo Zhang, Beijingjiaotong</a></li>
<li><a href="https://www.cvia.uni-konstanz.de/code-and-datasets/" target="_blank" rel="external">Computer Vision and Image Analysis, Konstanz University </a></li>
<li><a href="https://sites.google.com/site/hgjeoncv/home" target="_blank" rel="external">Hae-Gon Jeon, Carnegie Mellon University </a></li>
<li><a href="http://marine.acfr.usyd.edu.au/research/plenoptic-imaging/" target="_blank" rel="external">Plenoptic Imaging, ACFR Marine,Sydney University </a></li>
<li><a href="http://chenlab.ece.cornell.edu/projects/MobileCamArray/#Data%20Code" target="_blank" rel="external">Advanced Multimedia Processing Lab -- Projects -- The Self-Reconfigurable Camera Array</a></li>
<li><a href="https://tcwang0509.github.io/" target="_blank" rel="external">Ting-Chun Wang's Homepage</a></li>
<li><a href="https://people.eecs.berkeley.edu/~pratul/" target="_blank" rel="external">Pratul Srinivasan， EECS Department at UC Berkeley</a></li>

<li><em>please add more :)</em></li>
</ul>
<h2 id="Deep-Learning-Related"><a href="#Deep-Learning-Related" class="headerlink" title="Deep Learning Related"></a>Deep Learning Related</h2><ul>
<li><a href="https://cn.mathworks.com/help/nnet/examples.html?s_cid=doc_flyout#bvljehw" target="_blank" rel="external">Deep Learning in Matlab</a></li>
<li><em>please add more :)</em></li>
</ul>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ul>
<li><a href="https://unsplash.com/" target="_blank" rel="external">Free Images</a></li>
<li><a href="http://i.mouto.org/#kodak" target="_blank" rel="external">mouto</a></li>
<li><a href="http://lab.mouto.org/" target="_blank" rel="external">Lab</a></li>
<li><a href="https://blog.metheno.net/" target="_blank" rel="external">Metheno</a></li>
<li><a href="http://x.mouto.org/wb/" target="_blank" rel="external">You Know</a></li>
</ul>
<h2 id="Convert-Latex-to-images"><a href="#Convert-Latex-to-images" class="headerlink" title="Convert Latex to images"></a>Convert Latex to images</h2><ul>
<li><a href="http://www.latex2png.com/" target="_blank" rel="external">Latex2png</a></li>
<li><a href="https://private.codecogs.com/latex/eqneditor.php" target="_blank" rel="external">Latex2html</a></li>
<li><a href="http://www.tlhiv.org/ltxpreview/" target="_blank" rel="external">Latex2svg</a></li>
</ul>
<p align="right">转自<a href="https://www.vincentqin.tech/collections/">https://www.vincentqin.tech/collections/</a>,有补充</p>

<p>&nbsp;</p>


